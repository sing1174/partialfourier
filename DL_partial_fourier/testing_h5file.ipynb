{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05496ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py  \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "# print(matplotlib.__version__)\n",
    "# matplotlib.use('Agg')\n",
    "import h5py  \n",
    "\n",
    "from PIL import Image\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import itertools\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63e69d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_size = int(218)\n",
    "\n",
    "pf_line = int(np.floor(matrix_size*0.45))\n",
    "pf_line_com = matrix_size-pf_line\n",
    "pf_line_o =int(np.floor(170*0.45)) \n",
    "SS_flag =0\n",
    "MS_flag =0\n",
    "EMS_flag =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a18a86ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = 'C:/Users/Asus/Documents/DL-Partial_fourier/calgary_multicoil/e15598s3_P54784.7.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04b8551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(data_file, 'r') as f: \n",
    "    kspace = f['kspace']\n",
    "    \n",
    "\n",
    "    kspace = np.transpose(kspace,(0, 2, 1, 3))\n",
    "    kspace_shape = kspace.shape;\n",
    "    \n",
    "    imaginary = kspace[:,:,:,0:12];    # Right now, I'm unsure about what is real and imaginary but currently this works.\n",
    "    real = kspace[:,:,:,12:24];\n",
    "    \n",
    "    data = real + imaginary*1j;\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c68283c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 170, 218, 12)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "142a36ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = data.shape\n",
    "freq= np.fft.ifftshift(data ,axes=0)\n",
    "freq = np.fft.ifft(freq,axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29949ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = np.sqrt(sz[0])*np.fft.fftshift(freq,axes=0)\n",
    "# data1 = np.sqrt(sz[0])*freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdc0e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(np.log(np.squeeze(abs(data[:,:, 20, 6]))-1e-10), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "551b9fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 170, 218, 12)\n"
     ]
    }
   ],
   "source": [
    "print(data1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65e84685",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = np.reshape(data1,(-1,1,sz[1],sz[2])) # change sz[2] and sz[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4eb7df26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072, 1, 170, 218)\n"
     ]
    }
   ],
   "source": [
    "print(data2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fac6142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(np.log(abs(data2[150,0, :, :])-1e-10), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1a0f557",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq= np.fft.ifftshift(data2 ,axes=(2,3))\n",
    "freq = np.fft.ifft2(freq,axes=(2,3))\n",
    "img = np.sqrt(sz[1]*sz[2])*np.fft.fftshift(freq,axes=(2,3)) # change sz[1] sz[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42c78023",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_ref = round(np.max(np.absolute(img)),15)\n",
    "img = img/scale_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b72a0928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072, 1, 170, 218)\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e713e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3747a8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow((abs(img[91,0, :, :])), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfb2160f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 170, 218)\n",
      "(3, 170, 218)\n"
     ]
    }
   ],
   "source": [
    "##single slice\n",
    "if SS_flag ==1:\n",
    "    img_ref  = img[1:sz[0]-1,:,:,:]*0\n",
    "    for k in range(1,sz[0]-1):\n",
    "        img_ref[k-1,:,:,:] = img[k,:,:,:]\n",
    "else:\n",
    "    img_ref = np.concatenate((img[1:sz[0]-1,:,:,:]*0,img[1:sz[0]-1,:,:,:]*0,img[1:sz[0]-1,:,:,:]*0),axis = 1)\n",
    "    for k in range(1,sz[0]-1):\n",
    "        img_ref[k-1,:,:,:] = np.concatenate((img[k,:,:,:],  img[k-1,:,:,:], img[k+1,:,:,:]), axis =0)\n",
    "        \n",
    "        if k == 1:\n",
    "            print(img[k,:,:,:].shape)\n",
    "            print(img_ref[k-1,:,:,:].shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e007230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(254, 3, 170, 218)\n"
     ]
    }
   ],
   "source": [
    "print(img_ref.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b66685dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##multi slice\n",
    "freq= np.fft.ifftshift(img_ref ,axes=(2,3))\n",
    "freq= np.fft.fft2(freq ,axes=(2,3))\n",
    "test_k= 1/np.sqrt(sz[1]*sz[2])*np.fft.fftshift(freq,axes=(2,3))   \n",
    "test_data = np.copy(test_k)\n",
    "test_data[:,0,:,:pf_line] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "743d1994",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############complementry sampling pattern\n",
    "if EMS_flag ==1:\n",
    "    test_data[:,1:3,:,pf_line_com:] = 0\n",
    "\n",
    "if MS_flag==1:\n",
    "    test_data[:,1:3,:,:pf_line] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d853465a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(254, 3, 170, 218)\n"
     ]
    }
   ],
   "source": [
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec543093",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = np.fft.ifftshift(test_data,axes=(2,3))\n",
    "freq = np.fft.ifft2(freq ,axes=(2,3))\n",
    "img_data = np.sqrt(sz[2]*sz[3])*np.fft.fftshift(freq,axes=(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca6a7e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow((abs(img_data[90,0, :, :])), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9718035",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_label =img_ref[:,0,:,:] -img_data[:,0,:,:]\n",
    "img_label =img_label.reshape(sz[0]-2,-1,sz[1],sz[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4311485a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254, 1, 170, 218)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be56d414",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgdataR = np.copy(np.real(img_data))\n",
    "imgdataI = np.copy(np.imag(img_data))\n",
    "\n",
    "imgdata = np.concatenate((imgdataR,imgdataI), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "imglabelR = np.copy(np.real(img_label))\n",
    "imglabelI = np.copy(np.imag(img_label))\n",
    "imglabel = np.concatenate((imglabelR,imglabelI), axis=1)\n",
    "\n",
    "\n",
    "imgfull=img_label[:,0,:,:] + img_data[:,0,:,:]\n",
    "imgfull =imgfull.reshape(sz[0]-2,-1,sz[1],sz[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5369b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254, 6, 170, 218)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97b5b2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254, 2, 170, 218)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imglabel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9907fc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_nor = np.fft.ifftshift(imgfull,axes=(2,3))  \n",
    "# k_nor= np.fft.fft2(k_nor ,axes=(2,3))\n",
    "# k_nor = 1/np.sqrt(sz[1]*sz[2])*np.fft.fftshift(k_nor,axes=(2,3))  \n",
    "\n",
    "# k_zero = np.fft.ifftshift(img_data,axes=(2,3))  \n",
    "# k_zero= np.fft.fft2(k_zero ,axes=(2,3)) \n",
    "\n",
    "# k_zero = 1/np.sqrt(sz[1]*sz[2])*np.fft.fftshift(k_zero,axes=(2,3))\n",
    "\n",
    "# k_label = np.fft.ifftshift(img_label,axes=(2,3))  \n",
    "# k_label= np.fft.fft2(k_label ,axes=(2,3))\n",
    "# k_label = 1/np.sqrt(sz[1]*sz[2])*np.fft.fftshift(k_label,axes=(2,3))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a41468b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16,int(sz[0]-20)):\n",
    "    D = torch.from_numpy(imgdata[i,:,:,:]).float()\n",
    "    L = torch.from_numpy(imglabel[i,:,:,:]).float()\n",
    "    data = {'k-space':D,'label':L}\n",
    "#         torch.save(data,current_file_data_save +'/train/'+str(idx)+'_'+str(i)+'.pth')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e9c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['k-space']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a34ebf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafb280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code below test model2_cpx.py file segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3454b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_16_D = []\n",
    "\n",
    "for i in range(16, min(16 + 16, sz[0] - 20)):  # Adjusted loop range to ensure we don't exceed image size\n",
    "    D = torch.from_numpy(imgdata[i, :, :, :]).float()\n",
    "    first_16_D.append(D)  # Add the tensor to the list with an added dimension\n",
    "\n",
    "first_16_D = torch.stack(first_16_D)  # Convert the list of tensors into a single tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7681c17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = first_16_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9570059",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1c86f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "or_im = x\n",
    "nsize = x.size()\n",
    "pf_1 = math.floor(nsize[3] * 0.40)\n",
    "pf_com_1 = nsize[3] - pf_1\n",
    "pf_0 = math.floor(nsize[2] * 0.40)\n",
    "pf_com_0 = nsize[2] - pf_0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019c3841",
   "metadata": {},
   "outputs": [],
   "source": [
    "or_k = torch.complex(or_im[:, 0, :, :], or_im[:, 1, :, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad7de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "or_k = torch.fft.ifftshift(or_k, dim=(1, 2))\n",
    "or_k = torch.fft.fft2(or_k, dim=(1, 2))\n",
    "or_k = 1 / math.sqrt(nsize[2] * nsize[3]) * torch.fft.fftshift(or_k, dim=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f88c56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y = x\n",
    "for i in range(3):\n",
    "    x = y\n",
    "    new_k = torch.complex(x[:, 0, :, :], x[:, 1, :, :])\n",
    "    new_k = torch.fft.ifftshift(new_k, dim=(1, 2))\n",
    "    new_k = torch.fft.fft2(new_k, dim=(1, 2))\n",
    "    new_k = 1 / math.sqrt(nsize[2] * nsize[3]) * torch.fft.fftshift(new_k, dim=(1, 2))\n",
    "    \n",
    "\n",
    "    \n",
    "    new_k[:, :pf_0, :] = or_k[:, :pf_0, :]\n",
    "    new_k[:, :, :pf_1] = or_k[:, :, :pf_1]\n",
    "    \n",
    "    new_k = torch.fft.ifftshift(new_k, dim=(1, 2))\n",
    "    new_k = torch.fft.ifft2(new_k, dim=(1, 2))\n",
    "    new_k = math.sqrt(nsize[2] * nsize[3]) * torch.fft.fftshift(new_k, dim=(1, 2))\n",
    "    \n",
    "    print(new_k.shape)\n",
    "    new_k = torch.stack((torch.real(new_k), torch.imag(new_k)), dim=1)\n",
    "    print(new_k.shape)\n",
    "    \n",
    "#     x = x + self.t * (new_k - or_im)\n",
    "\n",
    "#     res = self.head(x)\n",
    "#     res = self.body(res)\n",
    "#     y = self.tail(res) + x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f85151",
   "metadata": {},
   "outputs": [],
   "source": [
    "or_k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5059559",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_k = torch.complex(y[:, 0, :, :], y[:, 1, :, :])\n",
    "new_k = torch.fft.ifftshift(new_k, dim=(1, 2))\n",
    "new_k = torch.fft.fft2(new_k, dim=(1, 2))\n",
    "new_k = 1 / math.sqrt(nsize[2] * nsize[3]) * torch.fft.fftshift(new_k, dim=(1, 2))\n",
    "new_k_ = or_k\n",
    "new_k_[:, :pf_0, :] = new_k[:, :pf_0, :]\n",
    "new_k_[:, :, :pf_1] = new_k[:, :, :pf_1]\n",
    "new_k = new_k_\n",
    "new_k = torch.fft.ifftshift(new_k, dim=(1, 2))\n",
    "new_k = torch.fft.ifft2(new_k, dim=(1, 2))\n",
    "new_k = math.sqrt(nsize[2] * nsize[3]) * torch.fft.fftshift(new_k, dim=(1, 2))\n",
    "y = torch.stack((torch.real(new_k), torch.imag(new_k)), dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
